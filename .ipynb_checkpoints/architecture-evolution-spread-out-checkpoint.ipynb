{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from IPython.core.debugger import set_trace\n",
    "# # Remember that if you convert to np.array dtype MUST be object or strings will get truncated\n",
    "\n",
    "# import database as db\n",
    "# import model_assembly as ma\n",
    "\n",
    "# db.create_tables()\n",
    "# db.create_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished inserting random motifs\n",
      "[('motifs/1.p', 1, 0.1, '', 1, 0), ('motifs/2.p', 1, 0.1, '', 1, 0), ('motifs/3.p', 1, 0.1, '', 1, 0), ('motifs/4.p', 1, 0.1, '', 1, 0), ('motifs/5.p', 1, 0.1, '', 1, 0), ('motifs/6.p', 1, 0.1, '', 1, 0), ('motifs/7.p', 1, 0.1, '', 1, 0), ('motifs/8.p', 1, 0.1, '', 1, 0), ('motifs/9.p', 1, 0.1, '', 1, 0), ('motifs/10.p', 1, 0.1, '', 1, 0)]\n",
      "Finished mutating motifs\n"
     ]
    }
   ],
   "source": [
    "# from mutate import create_working_set_of_mutants\n",
    "\n",
    "# create_random_mutants(level = 1, num_threads = 4, mutate_existing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "  0%|          | 0/110 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of motifs: 110\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5c06ce9eaf6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/New-Projects/AutoML/evo-search/train.py\u001b[0m in \u001b[0;36mtrain_level\u001b[0;34m(level)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmotif_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmotif\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmotifs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mtrain_motif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmotif_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmotif\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/New-Projects/AutoML/evo-search/train.py\u001b[0m in \u001b[0;36mtrain_motif\u001b[0;34m(motif_id, motif, level, batch_size, baseline_accuracy)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         verbose = 2)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mcurrent_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1900\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1901\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1640\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train import train_level\n",
    "\n",
    "import database as db\n",
    "motifs = [motif[0] for motif in db.select(\"\"\"SELECT rowid FROM motifs\"\"\")]\n",
    "for motif_id in motifs:\n",
    "    statement = \"\"\"UPDATE motifs SET trained = 0 WHERE rowid = {}\"\"\".format(motif_id)\n",
    "    db.update(statement)\n",
    "\n",
    "train_level(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T20:08:29.370756Z",
     "start_time": "2017-12-12T20:08:29.365534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic experiment plan:\n",
    "# get a two player mcts to work with the basic graph structure\n",
    "\n",
    "# train for ~10 minutes and then let the network start to learn\n",
    "# the network will output a softmax of possible locations\n",
    "# and and a softmax of layer types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-12T20:08:22.782196Z",
     "start_time": "2017-12-12T20:08:22.682775Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "G = np.array([\n",
    "       ['', 'conv2d1x1', 'conv2d1x1'],\n",
    "       ['', '', 'conv2d1x1'],\n",
    "       ['', '', '']\n",
    "    ])\n",
    "\n",
    "max_layers = 10\n",
    "\n",
    "shape = np.zeros((3 * max_layers, 3 * max_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-13T19:51:00.906948Z",
     "start_time": "2017-12-13T19:51:00.601665Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.datasets import cifar10, mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras import utils as np_utils\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, percentage = np.random.uniform(.1, .9), dataset = cifar10, augment_data = True):\n",
    "        self.percentage = percentage\n",
    "        \n",
    "        (self.X_train, self.y_train), (self.X_test, self.y_test) = dataset.load_data()\n",
    "\n",
    "        print(\"WARNING: number of categories is hardcoded, should make dynamic\")\n",
    "        self.y_train = np_utils.to_categorical(self.y_train, 10)\n",
    "        self.y_test = np_utils.to_categorical(self.y_test, 10)\n",
    "\n",
    "        if augment_data:\n",
    "            self.train_datagen = ImageDataGenerator(\n",
    "                  rotation_range=40,\n",
    "                  width_shift_range=0.2,\n",
    "                  height_shift_range=0.2,\n",
    "                  shear_range=0.2,\n",
    "                  zoom_range=0.2,\n",
    "                  horizontal_flip=True,\n",
    "                  fill_mode='nearest')\n",
    "        else:\n",
    "            self.train_datagen = ImageDataGenerator()\n",
    "\n",
    "        self.test_datagen = ImageDataGenerator()\n",
    "\n",
    "        self.X_train = self.X_train.astype('float32') / 255\n",
    "        self.X_test = self.X_test.astype('float32') / 255\n",
    "\n",
    "        X_train_mean = np.mean(self.X_train, axis = 0)\n",
    "        self.X_train -= X_train_mean\n",
    "        self.X_test -= X_train_mean\n",
    "\n",
    "        self.X_val, self.X_test, self.y_val, self.y_test = train_test_split(\n",
    "            self.X_test, self.y_test, test_size = 0.5)\n",
    "        \n",
    "        self.X_train_subset = self.X_train[:int(len(self.X_train) * self.percentage)]\n",
    "        self.y_train_subset = self.y_train[:int(len(self.y_train) * self.percentage)]\n",
    "        \n",
    "        self.X_val_subset = self.X_val[:int(len(self.X_val) * self.percentage)]\n",
    "        self.y_val_subset = self.y_val[:int(len(self.y_val) * self.percentage)]\n",
    "        \n",
    "        self.X_test_subset = self.X_test[:int(len(self.X_test) * self.percentage)]\n",
    "        self.y_test_subset = self.y_test[:int(len(self.y_test) * self.percentage)]\n",
    "        \n",
    "    def create_generators(self, batch_size = 32):\n",
    "        self.train_steps = int(len(self.X_train) * self.percentage) // batch_size\n",
    "        self.val_steps = int(len(self.X_val) * self.percentage) // batch_size\n",
    "        \n",
    "        train_generator = self.train_datagen.flow(\n",
    "                self.X_train_subset, self.y_train_subset,\n",
    "                batch_size = batch_size)\n",
    "\n",
    "        val_generator = self.test_datagen.flow(\n",
    "                self.X_val_subset, self.y_val_subset,\n",
    "                batch_size = batch_size)\n",
    "\n",
    "        test_generator = self.test_datagen.flow(\n",
    "                self.X_test_subset, self.y_test_subset,\n",
    "                batch_size = batch_size)\n",
    "        \n",
    "        ds.train_generator = train_generator\n",
    "        ds.val_generator = val_generator\n",
    "        ds.test_generator = test_generator\n",
    "\n",
    "        return train_generator, val_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-13T16:32:30.805028Z",
     "start_time": "2017-12-13T16:32:30.764785Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-13T16:32:31.206184Z",
     "start_time": "2017-12-13T16:32:31.197901Z"
    }
   },
   "outputs": [],
   "source": [
    "# passed\n",
    "# test = np.zeros(grid_size)\n",
    "\n",
    "# for i in range(9):\n",
    "#     test[i] = i\n",
    "    \n",
    "# flattened_test = flatten_matrix(test)\n",
    "# unflatten_matrix(flattened_test), test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     what do I want\n",
    "# I want the probabilities (softmax) for what position to change\n",
    "# I also want the probabilities of how I should change it\n",
    "# whether or not it is a good decision will depend on if it decreases or increases accuracy (after fine tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_level():\n",
    "    return np.argmax(select(\"\"\"SELECT DISTINCT level FROM motifs\"\"\".format(max_level)))\n",
    "\n",
    "def get_reasonable_moves():\n",
    "    select(\"\"\"SELECT * FROM motifs WHERE level = {}\"\"\".format(get_max_level()))\n",
    "    \n",
    "\n",
    "#     move_probabilities = Input(shape = len(primatives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-13T17:22:21.339921Z",
     "start_time": "2017-12-13T17:22:21.333175Z"
    }
   },
   "outputs": [],
   "source": [
    "primitives = [\"conv2d1x1\", \"conv2d3x3\", \"conv2d5x5\", \n",
    "              \"conv2dstride1x1\", \"conv2dstride3x3\", \"conv2dstride5x5\", \n",
    "              \"conv2dsep1x1\", \"conv2dsep3x3\", \"conv2dsep5x5\",\n",
    "              \"conv2dsepstride1x1\", \"conv2dsepstride3x3\", \"conv2dsepstride5x5\",\n",
    "             ]\n",
    "\n",
    "# all are assume to be conv - batchnorm - relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-13T17:22:21.991226Z",
     "start_time": "2017-12-13T17:22:21.986843Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_primitives():\n",
    "#     return select(\"\"\"SELECT * from primitives\"\"\")\n",
    "\n",
    "# primitives = get_primitives()\n",
    "\n",
    "# need hierarchy or mixture of softmaxes for the large number of move possibilties\n",
    "# idea: try to use the MCTS or something else to narrow down the possible reasonable moves, or\n",
    "# to only include the top level or two levels of motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-13T17:29:32.212335Z",
     "start_time": "2017-12-13T17:29:25.845614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: number of categories is hardcoded, should make dynamic\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset(percentage=1,\n",
    "             augment_data=False)\n",
    "\n",
    "train_generator, val_generator, test_generator = ds.create_generators(\n",
    "    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-13T17:26:56.972041Z",
     "start_time": "2017-12-13T17:26:56.902415Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications import MobileNet\n",
    "from keras import layers\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from clr_callback import CyclicLR\n",
    "\n",
    "def fit_model():\n",
    "    clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "    \n",
    "    net.compile(optimizer = \"sgd\",\n",
    "         loss = \"categorical_crossentropy\",\n",
    "         metrics = [\"acc\"])\n",
    "    net.fit_generator(train_generator, ds.train_steps, val_generator, ds.val_steps, callbacks = [clr])\n",
    "\n",
    "vec_length = flatten_matrix(np.zeros(grid_size)).shape[0]\n",
    "\n",
    "def create_conv_net():\n",
    "    previous_state = Input(shape = grid_size + (1,))\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                            input_shape=(9, 9, 1))(previous_state)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    \n",
    "    predicted_type = layers.Dense(len(primitives), activation='softmax')(x)\n",
    "    predicted_location = layers.Dense(vec_length, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=previous_state, outputs = [predicted_type, predicted_location])\n",
    "    \n",
    "    return model\n",
    "\n",
    "net = create_conv_net()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_shape = (32, 32, 3)\n",
    "# mcts = MCTSearcher(b_search, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_seeds():\n",
    "#     seeds = []\n",
    "\n",
    "#     for i in range(len(trainable_indices)):\n",
    "#         seeds.append({\"index\": trainable_indices[i],\n",
    "#                      \"lr\": np.random.})\n",
    "\n",
    "# gene_pool = []\n",
    "\n",
    "# state = gene_pool\n",
    "\n",
    "# mcts = MCTS()\n",
    "\n",
    "# probas = mcts.search()\n",
    "\n",
    "# inputs = [state, probas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import clr_callback as clr\n",
    "# from keras.optimizers import SGD\n",
    "# from keras.applications import MobileNet\n",
    "\n",
    "# def get_primatives():\n",
    "#     return select(\"\"\"SELECT * from primatives\"\"\")\n",
    "\n",
    "# vec_length = flatten_matrix(np.zeros(grid_size)).shape[0]\n",
    "\n",
    "# primatives = get_primatives()\n",
    "\n",
    "# def create_conv_net():\n",
    "#     mb = MobileNet(input_shape = grid_size + (1,), include_top=True)\n",
    "    \n",
    "#     x = layers.Conv2D(32, (3, 3), activation='relu',\n",
    "#                             input_shape=(9, 9, 1))(previous_state)\n",
    "#     x = layers.MaxPooling2D((2, 2))(x)\n",
    "#     x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "#     x = layers.MaxPooling2D((2, 2))(x)\n",
    "#     x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "#     x = layers.MaxPooling2D((2, 2))(x)\n",
    "#     x = layers.Flatten()(x)\n",
    "#     x = layers.Dense(512, activation='relu')(x)\n",
    "#     predicted_type = layers.Dense(len(primatives), activation='softmax')(x)\n",
    "#     predicted_location = layers.Dense(vec_length, activation='softmax')(x)\n",
    "#     model = Model(inputs=previous_state, outputs = [predicted_type, predicted_location])\n",
    "#     model.compile(optimizer = SGD(lr=clr()),\n",
    "#          loss = \"categorical_crossentropy\",\n",
    "#          metrics = [\"acc\"])\n",
    "#     return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
