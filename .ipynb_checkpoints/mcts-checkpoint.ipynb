{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T18:58:08.131185Z",
     "start_time": "2017-12-18T18:58:08.123747Z"
    }
   },
   "outputs": [],
   "source": [
    "# primitives = [\"conv2d1x1\", \"conv2d3x3\",\n",
    "# #               , \"conv2d5x5\",\n",
    "# #               \"conv2dstride1x1\", \"conv2dstride3x3\", \"conv2dstride5x5\",\n",
    "#               \"conv2dsep1x1\", \"conv2dsep3x3\",\n",
    "# #               \"conv2dsep5x5\",\n",
    "# #               \"conv2dsepstride1x1\", \"conv2dsepstride3x3\", \"conv2dsepstride5x5\",\n",
    "#               ]\n",
    "\n",
    "primitives = [1, 2,\n",
    "#               , \"conv2d5x5\",\n",
    "#               \"conv2dstride1x1\", \"conv2dstride3x3\", \"conv2dstride5x5\",\n",
    "              3, 4\n",
    "#               \"conv2dsep5x5\",\n",
    "#               \"conv2dsepstride1x1\", \"conv2dsepstride3x3\", \"conv2dsepstride5x5\",\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T18:58:08.525261Z",
     "start_time": "2017-12-18T18:58:08.508892Z"
    }
   },
   "outputs": [],
   "source": [
    "def getUntriedMoves(neighborsCache):\n",
    "    untriedMoves = []\n",
    "    \n",
    "    for (i, j) in neighborsCache:\n",
    "        move = dict({})\n",
    "        move[\"i\"] = i\n",
    "        move[\"j\"] = j\n",
    "        for p in primitives:\n",
    "            move[\"primitive\"] = p\n",
    "            untriedMoves.append(deepcopy(move))\n",
    "    \n",
    "    return untriedMoves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T18:58:29.023501Z",
     "start_time": "2017-12-18T18:58:09.169066Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: number of categories is hardcoded, should make dynamic\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.datasets import cifar10, mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras import utils as np_utils\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, percentage = np.random.uniform(.1, .9), dataset = cifar10, augment_data = True):\n",
    "        self.percentage = percentage\n",
    "        \n",
    "        (self.X_train, self.y_train), (self.X_test, self.y_test) = dataset.load_data()\n",
    "\n",
    "        print(\"WARNING: number of categories is hardcoded, should make dynamic\")\n",
    "        self.y_train = np_utils.to_categorical(self.y_train, 10)\n",
    "        self.y_test = np_utils.to_categorical(self.y_test, 10)\n",
    "\n",
    "        if augment_data:\n",
    "            self.train_datagen = ImageDataGenerator(\n",
    "                  rotation_range=40,\n",
    "                  width_shift_range=0.2,\n",
    "                  height_shift_range=0.2,\n",
    "                  shear_range=0.2,\n",
    "                  zoom_range=0.2,\n",
    "                  horizontal_flip=True,\n",
    "                  fill_mode='nearest')\n",
    "        else:\n",
    "            self.train_datagen = ImageDataGenerator()\n",
    "\n",
    "        self.test_datagen = ImageDataGenerator()\n",
    "\n",
    "        self.X_train = self.X_train.astype('float32') / 255\n",
    "        self.X_test = self.X_test.astype('float32') / 255\n",
    "\n",
    "        X_train_mean = np.mean(self.X_train, axis = 0)\n",
    "        self.X_train -= X_train_mean\n",
    "        self.X_test -= X_train_mean\n",
    "\n",
    "        self.X_val, self.X_test, self.y_val, self.y_test = train_test_split(\n",
    "            self.X_test, self.y_test, test_size = 0.5)\n",
    "        \n",
    "        self.X_train_subset = self.X_train[:int(len(self.X_train) * self.percentage)]\n",
    "        self.y_train_subset = self.y_train[:int(len(self.y_train) * self.percentage)]\n",
    "        \n",
    "        self.X_val_subset = self.X_val[:int(len(self.X_val) * self.percentage)]\n",
    "        self.y_val_subset = self.y_val[:int(len(self.y_val) * self.percentage)]\n",
    "        \n",
    "        self.X_test_subset = self.X_test[:int(len(self.X_test) * self.percentage)]\n",
    "        self.y_test_subset = self.y_test[:int(len(self.y_test) * self.percentage)]\n",
    "        \n",
    "    def create_generators(self, batch_size = 32):\n",
    "        self.train_steps = int(len(self.X_train) * self.percentage) // batch_size\n",
    "        self.val_steps = int(len(self.X_val) * self.percentage) // batch_size\n",
    "        \n",
    "        train_generator = self.train_datagen.flow(\n",
    "                self.X_train_subset, self.y_train_subset,\n",
    "                batch_size = batch_size)\n",
    "\n",
    "        val_generator = self.test_datagen.flow(\n",
    "                self.X_val_subset, self.y_val_subset,\n",
    "                batch_size = batch_size)\n",
    "\n",
    "        test_generator = self.test_datagen.flow(\n",
    "                self.X_test_subset, self.y_test_subset,\n",
    "                batch_size = batch_size)\n",
    "        \n",
    "        ds.train_generator = train_generator\n",
    "        ds.val_generator = val_generator\n",
    "        ds.test_generator = test_generator\n",
    "\n",
    "        return train_generator, val_generator, test_generator\n",
    "    \n",
    "ds = Dataset(percentage=1,\n",
    "             augment_data=False)\n",
    "\n",
    "train_generator, val_generator, test_generator = ds.create_generators(\n",
    "    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T18:58:29.188218Z",
     "start_time": "2017-12-18T18:58:29.030796Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, move = None, parent = None, state = None):\n",
    "        self.move = move\n",
    "        self.parentNode = parent\n",
    "        self.childNodes = []\n",
    "        self.wins = 0\n",
    "        self.visits = 0\n",
    "        self.weights = None\n",
    "        self.untriedMoves = deepcopy(state.legalMoves)\n",
    "        \n",
    "    def UCTSelectChild(self):\n",
    "        s = sorted(self.childNodes, key = lambda c: c.wins/c.visits + sqrt(2*log(self.visits)/c.visits))[-1]\n",
    "        \n",
    "    def AddChild(self, m, s):\n",
    "        n = Node(move = m, parent = self, state = s)\n",
    "        self.childNodes.append(n)\n",
    "        return n\n",
    "\n",
    "    def Update(self, result):\n",
    "        self.visits += 1\n",
    "        self.wins += result\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"[M:\" + str(self.move) + \" W/V:\" + str(self.wins) + \"/\" + str(self.visits) + \" U:\" + str(self.untriedMoves) + \"]\"\n",
    "    \n",
    "    def TreeToString(self, indent):\n",
    "        s = self.IndentString(indent) + str(self)\n",
    "        for c in self.childNodes:\n",
    "            s += c.TreeToString(indent+1)\n",
    "        return s\n",
    "    \n",
    "    def IndentString(self, indent):\n",
    "        s = \"\\n\"\n",
    "        for i in range(1, indent+1):\n",
    "            s += \"| \"\n",
    "        return s\n",
    "    \n",
    "    def ChildrenToString(self):\n",
    "        s = \"\"\n",
    "        for c in self.childNodes:\n",
    "            s += str(c) + \"\\n\"\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T18:58:29.288970Z",
     "start_time": "2017-12-18T18:58:29.193683Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "from clr_callback import CyclicLR\n",
    "\n",
    "\n",
    "def fitAutoEnc(model, X_train, X_test, clr):\n",
    "    model.fit(X_train, X_train,\n",
    "              epochs=2,\n",
    "              batch_size=64,\n",
    "              validation_data=(X_test, X_test),\n",
    "              callbacks=[clr])\n",
    "\n",
    "\n",
    "def fitDataset(model, ds, clr):\n",
    "    model.fit_generator(generator=ds.train_generator, steps_per_epoch=ds.train_steps,\n",
    "                        epochs=2, verbose=1, callbacks=[clr], validation_data=ds.val_generator,\n",
    "                        validation_steps=ds.val_steps)\n",
    "\n",
    "\n",
    "def finetune(model, ds=ds, loss=\"binary_crossentropy\", metrics=None):\n",
    "    optim = SGD(nesterov=True)\n",
    "    base_lr = 0.001\n",
    "    max_lr = 0.006\n",
    "    clr = CyclicLR(base_lr=base_lr, max_lr=max_lr,\n",
    "                   step_size=2000., mode='triangular')\n",
    "\n",
    "    model.compile(optimizer=optim,\n",
    "                  loss=loss,\n",
    "                  metrics=metrics)\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        print(layer.trainable)\n",
    "\n",
    "    fitDataset(model, ds, clr)\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=loss,\n",
    "                  metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T18:58:29.413238Z",
     "start_time": "2017-12-18T18:58:29.291424Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "def load_weights(model, weights, debug = False, doFinetune = True,\n",
    "                metrics = None, ):\n",
    "    if weights is None:\n",
    "        return model\n",
    "    \n",
    "    origModelWeights = deepcopy(model.get_weights())\n",
    "    weight_idx = 0\n",
    "    setWeights = True\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if layer.get_weights() != []:\n",
    "            if layer.get_weights()[0].shape == weights[weight_idx].shape:\n",
    "                temp = []\n",
    "                for j, weight in enumerate(layer.get_weights()):\n",
    "                    if weight_idx+j < len(weights)-1:\n",
    "                        weight_idx += j\n",
    "                        temp.append(weights[weight_idx])\n",
    "                    else:\n",
    "                        setWeights = False\n",
    "                if setWeights:\n",
    "                    layer.set_weights(temp)\n",
    "                    if finetune: layer.trainable = False\n",
    "                    weight_idx += 1\n",
    "                if debug: print(\"Weight group {} of {} used\".format(weight_idx, len(weights)))\n",
    "                if debug: print(layer.name, \"Weight Changed\")\n",
    "        else:\n",
    "            if debug: print(layer.name, \"Weight Not Changed\")\n",
    "            \n",
    "    if debug: \n",
    "        for weight in weights[weight_idx-1:]:\n",
    "            print(weight.shape)\n",
    "    \n",
    "    assert (origModelWeights[0] != model.get_weights()[0]).any()\n",
    "    \n",
    "    if doFinetune:\n",
    "        model = finetune(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T18:59:45.017069Z",
     "start_time": "2017-12-18T18:59:42.870859Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import *\n",
    "import random\n",
    "from model_assembly import fitWithCLR, assemble_model \n",
    "from copy import deepcopy\n",
    "from IPython.core.debugger import set_trace\n",
    "from os.path import exists, join\n",
    "from os import mkdir\n",
    "\n",
    "class EvoSearchState:\n",
    "    def __init__(self, kwargs={}):\n",
    "        self.net = kwargs.get(\"net\", None)\n",
    "        self.netReady = kwargs.get(\"netReady\", False)\n",
    "        self.graph = kwargs.get(\"graph\", np.zeros((30, 30)))\n",
    "        self.numNeighbors = kwargs.get(\"numNeighbors\", 3)\n",
    "        self.prevAcc = kwargs.get(\"prevAcc\", None)\n",
    "        self.prevModel = kwargs.get(\"prevModel\", None)\n",
    "        self.bestAcc = kwargs.get(\"bestAcc\", None)\n",
    "        self.bestGraph = kwargs.get(\"bestGraph\", None)\n",
    "        self.bestModel = kwargs.get(\"bestAcc\", None)\n",
    "        self.coords = kwargs.get(\"coords\", (-2, -1))\n",
    "        self.legalMoves = kwargs.get(\"legalMoves\", self.getLegalMoves())\n",
    "        if not exists(\"weights\"):\n",
    "            mkdir(\"weights\")\n",
    "\n",
    "    def Clone(self):\n",
    "        kwargs = {\"net\": self.net, \n",
    "                  \"netReady\": self.netReady,\n",
    "                  \"graph\": self.graph, \n",
    "                  \"numNeighbors\": self.numNeighbors,\n",
    "                  \"prevAcc\": self.prevAcc,\n",
    "                  \"prevModel\": self.prevModel,\n",
    "                  \"bestAcc\": self.bestAcc,\n",
    "                  \"bestGraph\": self.bestGraph,\n",
    "                  \"bestModel\": self.bestModel,\n",
    "                  \"legalMoves\": self.legalMoves,\n",
    "                  \"coords\": self.coords}\n",
    "        return EvoSearchState(kwargs)\n",
    "\n",
    "    def DoMove(self, move):\n",
    "        self.graph[move[\"i\"]][move[\"j\"]] = move[\"primitive\"]\n",
    "        self.coords = (move[\"i\"], move[\"j\"])\n",
    "        self.legalMoves = self.getLegalMoves()\n",
    "\n",
    "    def flattenMatrix(self, M, index=None):\n",
    "        flattened_vec = []\n",
    "        returnIndex = None\n",
    "\n",
    "        for i in range(M.shape[0]):\n",
    "            for j in range(M.shape[1]):\n",
    "                if j > i and j < i + 3:\n",
    "                    flattened_vec.append(M[i, j])\n",
    "                    if index is not None and i == index[0] and j == index[1]:\n",
    "                        returnIndex = len(flattened_vec) - 1\n",
    "\n",
    "        return np.asarray(flattened_vec), returnIndex\n",
    "\n",
    "    def unflattenVector(self, v, index=None):\n",
    "        graph = self.graph\n",
    "        M = np.zeros((graph.shape[0], graph.shape[1]))\n",
    "        returnIndex = None\n",
    "\n",
    "        cnt = 0\n",
    "        for i in range(size[0]):\n",
    "            for j in range(size[1]):\n",
    "                if j > i and j < i + 3:\n",
    "                    if index is not None and index == cnt:\n",
    "                        returnIndex = (i, j)\n",
    "                    M[i][j] = v[cnt]\n",
    "                    cnt += 1\n",
    "\n",
    "        return np.asarray(M), returnIndex\n",
    "\n",
    "    def getNeighborsCache(self):\n",
    "        (i, j) = self.coords\n",
    "        numNeighbors = self.numNeighbors\n",
    "        graph = self.graph\n",
    "\n",
    "        def twosFloor(num):\n",
    "            if num % 2 == 1:\n",
    "                return (num - 1) // 2\n",
    "            else:\n",
    "                return num // 2\n",
    "\n",
    "        def shiftedTwosFloor(num):\n",
    "            num += 3\n",
    "            if num % 2 == 1:\n",
    "                return (num - 1) // 2\n",
    "            else:\n",
    "                return num // 2\n",
    "\n",
    "#         if j < 0 or j > graph.shape[0] - 1 or i < 0 or i > graph.shape[0] - 1:\n",
    "#             raise Exception(\"i or j are out of bounds. i: %d, j: %d\" % (i, j))\n",
    "        neighbors = []\n",
    "\n",
    "        _, idx = self.flattenMatrix(graph, (i, j))\n",
    "        if i == -1 and j == 0:\n",
    "            idx = -1\n",
    "        elif i == -2 and j == -1:\n",
    "            idx = -2\n",
    "\n",
    "        for k_ in range(numNeighbors):\n",
    "            k = k_ + 1\n",
    "    #         if idx - k >= 0:\n",
    "    #             negNeighbor = (twosFloor(idx - k), shiftedTwosFloor(idx - k))\n",
    "    #             neighbors.append(negNeighbor)\n",
    "            if idx + k < int(graph.shape[0] * 2) - 3:\n",
    "                posNeighbor = (twosFloor(idx + k), shiftedTwosFloor(idx + k))\n",
    "                neighbors.append(posNeighbor)\n",
    "        return neighbors\n",
    "\n",
    "    def getLegalMoves(self):\n",
    "        neighborsCache = self.getNeighborsCache()\n",
    "        legalMoves = []\n",
    "        for (i, j) in neighborsCache:\n",
    "            for p in primitives:\n",
    "                move = dict({})\n",
    "                move[\"i\"] = i\n",
    "                move[\"j\"] = j\n",
    "                move[\"primitive\"] = p\n",
    "                legalMoves.append(move)\n",
    "                \n",
    "        return legalMoves\n",
    "\n",
    "    #         should start random\n",
    "# Should I limit it to expanding the current board state (no overwrites?)\n",
    "# that would complicate the softmax and prevent the network from fixing itself\n",
    "# but might prevent undoing it's own training\n",
    "\n",
    "    def GetMove(self, untriedMoves):\n",
    "        #         should return the 9x9 grid around where the last move was made.\n",
    "        # default would be upsper left hand corner\n",
    "        #         if self.moveCounter > 100:\n",
    "        #             net.train\n",
    "        if self.netReady:\n",
    "            predictions = self.net.predict(self.graph)\n",
    "            location = predictions[0]\n",
    "            primitive = predictions[1]\n",
    "            (i, j) = self.unflattenVector(probas, np.max(probas))\n",
    "            move = dict({})\n",
    "            move[\"i\"] = i\n",
    "            move[\"j\"] = j\n",
    "            move[\"primitive\"] = np.max(primitive)\n",
    "            return move\n",
    "        else:\n",
    "            return random.choice(untriedMoves)\n",
    "\n",
    "    def isFinished(self, numNodes, weights):\n",
    "        model = assemble_model(self.graph.tolist())\n",
    "        model.summary()\n",
    "        if weights is not None:\n",
    "            model = load_weights(model, weights, doFinetune=True, debug=False)\n",
    "            \n",
    "        acc = fitWithCLR(model, ds).history['val_acc'][-1]\n",
    "\n",
    "        if acc is not None and (self.prevAcc is None or acc > self.prevAcc):\n",
    "            print(\"prevAcc: {}, newAcc: {}\".format(self.prevAcc, acc))\n",
    "            self.prevAcc = acc\n",
    "            self.prevGraph = self.graph\n",
    "            self.prevModel = model\n",
    "            model.save_weights(join(\"weights\", \"{}.h5\".format(numNodes)))\n",
    "            return False, model.get_weights()\n",
    "        else:\n",
    "            print(\"Termination condition reached\")\n",
    "            return True, None\n",
    "\n",
    "    def GetResult(self, numNodes):\n",
    "        model = assemble_model(self.graph.tolist())\n",
    "#         Not considering the last option might be bad, but it's probably worth it since we want \n",
    "# the best performing model\n",
    "        if self.bestAcc is None or self.prevAcc > self.bestAcc:\n",
    "            print(\"bestAcc: {}, newAcc: {}\".format(self.bestAcc, self.prevAcc))\n",
    "            self.bestAcc = self.prevAcc\n",
    "            self.bestGraph = self.prevGraph\n",
    "            self.bestModel = self.prevModel\n",
    "#             model.save_weights(join(\"weights\", \"{}.h5\".format(numNodes)))\n",
    "            model.save(\n",
    "                join(\"weights\", \"best_model_node_{}.h5\".format(numNodes)))\n",
    "            print(\"Success\")\n",
    "            return 1\n",
    "        else:\n",
    "            print(\"Failure\")\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T18:59:45.335552Z",
     "start_time": "2017-12-18T18:59:45.019720Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from keras.models import load_model\n",
    "\n",
    "def UCT(rootState, maxIters, verbose=False):\n",
    "    nodeLookup = dict({})\n",
    "\n",
    "    try:\n",
    "        rootNode = pickle.load(open(\"MCTS.p\", \"rb\"))\n",
    "        bestGraph = pickle.load(open(\"bestGraph.p\", \"rb\"))\n",
    "        bestModel = load_model(\"bestModel.h5\")\n",
    "        bestAcc = pickle.load(open(\"bestAcc.p\", \"rb\"))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        rootNode = Node(state=rootState)\n",
    "        bestAcc = None\n",
    "\n",
    "    origAcc = bestAcc\n",
    "\n",
    "    for i in range(maxIters):\n",
    "        print(\"On iteration {}\".format(i))\n",
    "        numNodes = 0\n",
    "        node = rootNode\n",
    "        state = rootState.Clone()\n",
    "\n",
    "        if bestAcc is not None:\n",
    "            state.bestAcc = bestAcc\n",
    "            state.bestGraph = bestGraph\n",
    "            state.bestModel = bestModel\n",
    "\n",
    "# if a node has no untriedMoves left and it IS NOT a leaf node, then select the node through UCT\n",
    "        while node.untriedMoves == [] and node.childNodes != []:\n",
    "            #         misleading name but I think select child refers to select a leaf action (ie train a network)\n",
    "            node = node.UCTSelectChild()\n",
    "            state.DoMove(node.move)\n",
    "\n",
    "        if node.untriedMoves != []:\n",
    "            finished = False\n",
    "            while not finished:\n",
    "                move = state.GetMove(node.untriedMoves)\n",
    "                node.untriedMoves.remove(move)\n",
    "#                 DoMove updates state.legalMoves\n",
    "                state.DoMove(move)\n",
    "#                 node.untriedMoves = state.getLegalMoves()\n",
    "                numNodes += 1\n",
    "                if node != rootNode:\n",
    "                    weights = node.parentNode.weights\n",
    "                else:\n",
    "                    weights = None\n",
    "                finished, wgts = state.isFinished(numNodes, weights)\n",
    "                node.weights = wgts\n",
    "                node = node.AddChild(move, state)\n",
    "\n",
    "        result = state.GetResult(numNodes)\n",
    "\n",
    "        while node != None:\n",
    "            node.Update(result)\n",
    "            node = node.parentNode\n",
    "\n",
    "        bestAcc = state.bestAcc\n",
    "        bestGraph = state.bestGraph\n",
    "        bestModel = state.bestModel\n",
    "\n",
    "        if i % 10 == 0 or i == maxIters - 1:\n",
    "            pickle.dump(rootNode, open(\"MCTS.p\", \"wb\"))\n",
    "            if bestAcc > origAcc:\n",
    "                bestModel.save(\"bestModel.h5\")\n",
    "                pickle.dump(bestGraph, open(\"bestGraph.p\", \"wb\"))\n",
    "                pickle.dump(bestAcc, open(\"bestAcc.p\", \"wb\"))\n",
    "\n",
    "#     if (verbose):\n",
    "#         print (rootNode.TreeToString(0))\n",
    "#     else:\n",
    "#         print (rootNode.ChildrenToString())\n",
    "\n",
    "    return bestAcc, bestGraph, bestModel, rootNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T18:59:45.383953Z",
     "start_time": "2017-12-18T18:59:45.338383Z"
    }
   },
   "outputs": [],
   "source": [
    "def RunMCTS():\n",
    "    state = EvoSearchState()\n",
    "#     while (state.GetMove() != None):\n",
    "    bestAcc, bestGraph, bestModel, rootNode = UCT(rootState = state, maxIters = 500, verbose = False)\n",
    "    print(\"Best Acc: {}\".format(bestAcc))\n",
    "    \n",
    "#     print(\"Best Move: {}\\n\".format(m))\n",
    "#     state.DoMove(m)\n",
    "#     if state.GetResult() == 1:\n",
    "#         print(\"Successful Architecture!\")\n",
    "#     else: \n",
    "#         print(\"Unsuccessful Architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T19:15:05.294398Z",
     "start_time": "2017-12-18T18:59:45.390765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On iteration 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                163850    \n",
      "=================================================================\n",
      "Total params: 163,978\n",
      "Trainable params: 163,946\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "Epoch 1/4\n",
      "781/781 [==============================] - 104s - loss: 1.8190 - acc: 0.3556 - val_loss: 1.6436 - val_acc: 0.4203\n",
      "Epoch 2/4\n",
      "781/781 [==============================] - 104s - loss: 1.6565 - acc: 0.4219 - val_loss: 1.5969 - val_acc: 0.4293\n",
      "Epoch 3/4\n",
      "781/781 [==============================] - 104s - loss: 1.5999 - acc: 0.4463 - val_loss: 1.5607 - val_acc: 0.4489\n",
      "Epoch 4/4\n",
      "781/781 [==============================] - 104s - loss: 1.5184 - acc: 0.4766 - val_loss: 1.4957 - val_acc: 0.4777\n",
      "prevAcc: None, newAcc: 0.47771474878444087\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_1 (Separabl (None, 32, 32, 16)        416       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                163850    \n",
      "=================================================================\n",
      "Total params: 164,458\n",
      "Trainable params: 164,394\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "input_2 Weight Not Changed\n",
      "Weight group 2 of 8 used\n",
      "conv2d_2 Weight Changed\n",
      "Weight group 5 of 8 used\n",
      "batch_normalization_2 Weight Changed\n",
      "activation_2 Weight Not Changed\n",
      "Weight group 6 of 8 used\n",
      "batch_normalization_3 Weight Changed\n",
      "activation_3 Weight Not Changed\n",
      "flatten_2 Weight Not Changed\n",
      "Weight group 6 of 8 used\n",
      "dense_2 Weight Changed\n",
      "(16,)\n",
      "(16384, 10)\n",
      "(10,)\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "Epoch 1/2\n",
      "781/781 [==============================] - 179s - loss: 0.2967 - val_loss: 0.2689\n",
      "Epoch 2/2\n",
      "781/781 [==============================] - 184s - loss: 0.2590 - val_loss: 0.2497\n",
      "Epoch 1/4\n",
      "487/781 [=================>............] - ETA: 80s - loss: 1.6330 - acc: 0.4324"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4cf5bd496951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRunMCTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-5c610c703cf7>\u001b[0m in \u001b[0;36mRunMCTS\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvoSearchState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     while (state.GetMove() != None):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbestAcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestGraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrootNode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUCT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrootState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxIters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Acc: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestAcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-93c40a489a17>\u001b[0m in \u001b[0;36mUCT\u001b[0;34m(rootState, maxIters, verbose)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mfinished\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwgts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misFinished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumNodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwgts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddChild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f214bb2380f2>\u001b[0m in \u001b[0;36misFinished\u001b[0;34m(self, numNodes, weights)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoFinetune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitWithCLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0macc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevAcc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevAcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/New-Projects/AutoML/evo-search/model_assembly.py\u001b[0m in \u001b[0;36mfitWithCLR\u001b[0;34m(model, ds, epochs, optim, finetune)\u001b[0m\n\u001b[1;32m    319\u001b[0m     return model.fit_generator(generator=ds.train_generator, steps_per_epoch=ds.train_steps, \n\u001b[1;32m    320\u001b[0m                                \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                                validation_steps=ds.val_steps)\n\u001b[0m",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RunMCTS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
